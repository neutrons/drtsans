#!/usr/bin/env python
"""Autoreduction script for EQSANS"""

import argparse
from copy import deepcopy
import datetime
import io
import json
import logging
from collections import namedtuple
import os
import re
import requests
import sys
import time
from typing import Union
import warnings

from plot_publisher import plot_heatmap, publish_plot
from mantid.dataobjects import EventWorkspace
from mantid.simpleapi import DeleteWorkspace, Integration, LoadEventNexus, mtd
from mantid.utils.logging import log_to_python as mtd_log_to_python
import numpy as np
import plotly.offline as pyo

import drtsans
from drtsans.redparams import reduction_parameters, update_reduction_parameters
from drtsans.samplelogs import SampleLogs
from drtsans.tof.eqsans.api import (
    load_all_files,
    reduce_single_configuration,
    plot_reduction_output,
    plotly_reduction_output,
)
from drtsans.tof.eqsans.meta_data import is_sample_run

# silently ignore all types of numerical errors (like divide by zero, overflow, etc.)
np.seterr(all="ignore")
warnings.filterwarnings("ignore", module="numpy")
CONDA_ENV = "sans-qa"

LOG_NAME = "autoreduce"
AUTOREDUCE_DIR = "/SNS/EQSANS/shared/autoreduce"
AUTOREDUCE_IPTS_DIR = "/SNS/EQSANS/IPTS-{ipts}/shared/autoreduce"  # e.g. /SNS/EQSANS/IPTS-12345/shared/autoreduce

TUBES_PER_EIGHTPACK = 8
TUBES_IN_DETECTOR1 = 192
PIXELS_PER_TUBE = 256


LogContext = namedtuple("LogContext", ["logger", "logfile", "error_buffer"])


def filelink(filepath: str) -> str:
    """Create an HTML link to a file path.

    Parameters
    ----------
    filepath : str
        The file path to be linked.

    Returns
    -------
    str
        An HTML anchor tag linking to the specified file path.
    """
    return f"<a href='file://{filepath}' target='_blank'>{filepath}</a>"


def configure_logger(log_name: str, output_dir: str, run_number: str) -> tuple[io.StringIO, str]:
    """Configure logging for the autoreduction process.

    Sets up file and error logging handlers for the autoreduction workflow. Redirects Mantid
    logging to Python's logging system and creates a buffer to capture error messages separately.

    Parameters
    ----------
    log_name
        name of the python logger to use for messages generated by the autoreduction script
    output_dir : str
        Directory path where the log file will be saved. The log file will be named 'autoreduce.log'.
    run_number: str
        The run number associated with the current reduction process. This is used to name the log file

    Returns
    -------
    io.StringIO
        A StringIO buffer containing error-level log messages. This buffer can be used to
        display errors in the final HTML report.
    str
        The path to the log file created in the specified output directory.

    Notes
    -----
    - Mantid logging is redirected to Python logging at INFO level
    - A file handler writes all INFO and above messages to `autoreduce.log`
    - A separate StringIO handler captures only ERROR and above messages
    - The root logger for 'autoreduce' is set to INFO level
    """
    # redirect Mantid Pocco logging to python logging
    mtd_log_to_python("information")
    logging.getLogger("Mantid").setLevel(logging.INFO)

    # create a file handler
    logfile = os.path.join(output_dir, f"{log_name}_{run_number}.log")
    file_handler = logging.FileHandler(logfile, mode="w")  # overwrite existing log file
    file_handler.setLevel(logging.INFO)
    logformat = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    file_handler.setFormatter(logging.Formatter(logformat))
    logging.getLogger().addHandler(file_handler)

    # create a stream handler for console output from loggers "Mantid" and log_name only
    stream_handler = logging.StreamHandler(sys.stdout)  # console output
    stream_handler.setLevel(logging.INFO)
    stream_handler.addFilter(lambda record: "Mantid" in record.name or log_name in record.name)
    logging.getLogger().addHandler(stream_handler)

    # Create a StringIO buffer and handler for error messages
    error_log_buffer = io.StringIO()
    error_log_handler = logging.StreamHandler(error_log_buffer)
    error_log_handler.setLevel(logging.ERROR)
    error_log_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))
    logging.getLogger().addHandler(error_log_handler)

    # add the handlers to the python root logger

    logging.getLogger(LOG_NAME).setLevel(logging.INFO)
    return error_log_buffer, logfile


def intensity_array(events: EventWorkspace) -> tuple:
    """
    Integrate intensities of each detector pixel.

    Parameters
    ----------
    events
        Raw events to be processed.

    Returns
    -------
    tuple
        A tuple containing:
        - x (numpy.ndarray): Array of tube indices.
        - y (numpy.ndarray): Array of pixel indices.
        - z (numpy.ma.MaskedArray): Log-transformed and masked intensity data.

    Notes
    -----
    - The function uses Mantid's `Integration` to process the data.
    """
    workspace_name = mtd.unique_hidden_name()
    intensities = Integration(InputWorkspace=events, OutputWorkspace=workspace_name)
    data = intensities.extractY().reshape(-1, TUBES_PER_EIGHTPACK, PIXELS_PER_TUBE).T
    data2 = data[:, [0, 4, 1, 5, 2, 6, 3, 7], :]  # tube indexes within an eightpack
    data2 = data2.transpose().reshape(-1, PIXELS_PER_TUBE)
    z = np.ma.masked_where(data2 < 1, data2)
    x = np.arange(TUBES_IN_DETECTOR1) + 1
    y = np.arange(PIXELS_PER_TUBE) + 1
    z = np.log(np.transpose(z))
    DeleteWorkspace(workspace_name)
    return x, y, z


def upload_report(run_number: str, plot_div: str, logger: logging.Logger):
    """
    Upload a plot to the livedata server for the EQSANS instrument.

    Parameters
    ----------
    run_number
        The run number associated with the plot.
    plot_div
        The HTML div containing the plot to be uploaded.
    logger
        Logger for logging upload status and errors.

    Notes
    -----
    - The function uses the `publish_plot` method to upload the plot.
    - If the upload fails due to an HTTP error, the exception is logged.
    """
    try:
        publish_plot("EQSANS", run_number, files={"file": plot_div})
    except requests.HTTPError:
        logger.exception("Publish plot failed")


def html_wrapper(report: Union[str, None], logger: logging.Logger) -> str:
    """Wraps a report (set of <dvi> elements) in a complete HTML document

    Adds the javascript engine (PlotLy.js) address, HTML head, and body tags.

    Parameters
    ----------
    report : str
        The HTML content to be wrapped. This should contain one or more <div> elements and possibly
        summary <table> elements.

    Returns
    -------
    str
        A complete HTML document as a string, with the provided report content embedded within the body.
    """
    js_version = pyo.get_plotlyjs_version()
    url = f"https://cdn.plot.ly/plotly-{js_version}.js"
    try:
        response = requests.head(url, timeout=5)
        assert response.status_code == 200
    except (requests.RequestException, AssertionError):
        logger.error(f"Plotly.js version {js_version} not found, using version 3.0.0 instead")
        url = "https://cdn.plot.ly/plotly-3.0.0.js"

    prefix = f"""<!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Plotly Chart</title>
        <script src="{url}"></script>
    </head>
    <body>

    """
    suffix = """

    </body>
    </html>
    """
    report = "" if report is None else report
    return prefix + report + suffix  # allow for report being `None`


def save_report(report: str, report_file: str, logger: logging.Logger):
    """
    Save an HTML plot to a file with the necessary JavaScript engine for rendering.

    Parameters
    ----------
    report
        The HTML content to be saved. This may contain one or more <div> elements
        and possibly summary <table> elements.
    report_file
        The path to the file where the HTML report will be saved.

    Notes
    -----
    - The saved file includes the Plotly JavaScript library to ensure the plot can be displayed in a web browser.
    - The function wraps the provided `report` with the required HTML structure.
    """
    with open(report_file, "w") as f:
        f.write(html_wrapper(report, logger))


def parse_command_arguments() -> argparse.Namespace:
    """
    Parse command-line arguments for the EQSANS autoreduction script.

    Returns
    -------
    argparse.Namespace
        An object containing the parsed command-line arguments:
        - events_file (str): Path to the Nexus events file.
        - outdir (str): Output directory path.
        - no_publish (bool): Flag to disable uploading the HTML report to the livedata server.

    Notes
    -----
    - The `--no_publish` flag prevents the report from being uploaded to the server.
    """
    parser = argparse.ArgumentParser(description="Autoreduction script for EQSANS")
    parser.add_argument("events_file", type=str, help="Path to the Nexus events file.")
    parser.add_argument("outdir", type=str, help="Output directory path.")
    parser.add_argument("--no_publish", action="store_true", help="Do not upload HTML report to the livedata server.")
    return parser.parse_args()


def reduce_non_sample(events: EventWorkspace):
    """
    Reduce events from a non-sample run by generating a heatmap plot of pixel intensities

    Parameters
    ----------
    events : EventWorkspace
        The Mantid EventWorkspace containing the raw events to be processed.

    Returns
    -------
    report (str): An HTML div containing the generated heatmap plot of pixel intensities
    """
    # Aggregate the events within each pixel as an intensity value
    x, y, z = intensity_array(events)

    # Generate the plot as an HTML div
    report = plot_heatmap(
        events.getRunNumber(),
        x.tolist(),
        y.tolist(),
        z.tolist(),
        x_title="Tube",
        y_title="Pixel",
        x_log=False,
        y_log=False,
        instrument="EQSANS",
        title="Counts per Pixel",
        publish=False,
    )
    return report


def reduce_sample(events: EventWorkspace, output_dir: str, logger: logging.Logger) -> str:
    """Reduce events from a sample run and generate comprehensive output files and plots.

    This function performs the complete reduction workflow for sample runs, including loading
    reduction options, validating configuration, reducing data, and generating output files
    and plots.

    Parameters
    ----------
    events : EventWorkspace
        The Mantid EventWorkspace containing the raw sample events to be reduced.
    output_dir : str
        Base output directory path for reduction files. If this matches the IPTS-specific
        autoreduce directory, a subdirectory with the run number will be created for outputs.
    logger
        Logger for logging reduction status and errors.

    Returns
    -------
    str
        An HTML string containing the complete reduction report, including:
        - Pixel intensity heatmap (from reduce_non_sample)
        - Plotly reduction output plots (pixel integrated intensity heatmap, I(Qx,Qy) heatmap, I(Q) profiles)

    Notes
    -----
    - Searches for reduction options in order of priority:
      1. `reduction_options_{run_number}.json` in output_dir
      2. `reduction_options.json` in IPTS autoreduce directory
      3. `reduction_options.json` in shared autoreduce directory
    - Automatically amends reduction parameters with run-specific information
    - Saves reduced data files, HDF5 log, and plots (*.png) to the output directory
    - Saves the final comprehensive reduction options to `reduction_options_{run_number}.json`
    """
    run_number = str(events.getRunNumber())  # e.g. "105584"
    ipts = SampleLogs(events).experiment_identifier.value[5:]  # e.g. "12345" when having IPTS-12345

    # find most appropriate reduction options and amend if necessary
    amendment = {}
    # Example: reduction_options_path == /SNS/EQSANS/IPTS-12345/shared/autoreduce/105584/reduction_options_105584.json
    reduction_options_path = os.path.join(output_dir, f"reduction_options_{run_number}.json")
    if os.path.exists(reduction_options_path) is False:
        amendment = {
            "iptsNumber": ipts,
            "sample": {"runNumber": run_number},
            "outputFileName": f"EQSANS_{run_number}",  # prefix for all output files
            "configuration": {"outputDir": output_dir},
        }
        # Example: reduction_options_path == /SNS/EQSANS/IPTS-12345/shared/autoreduce/reduction_options.json
        reduction_options_path = os.path.join(AUTOREDUCE_IPTS_DIR.format(ipts=ipts), "reduction_options.json")
        if os.path.exists(reduction_options_path) is False:
            #  Fallback: /SNS/EQSANS/shared/autoreduce/reduction_options.json
            reduction_options_path = os.path.join(AUTOREDUCE_DIR, "reduction_options.json")
            amendment["beamCenter"] = {"runNumber": run_number}
    logger.info(f"reduce_sample: Loading reduction options from {reduction_options_path}")

    footer = (
        "<b>Note:</b> the links below can't be open directly. Instead, copy the link address "
        "and paste it in a new browser tab.<br>\n"
    )
    footer += "<table border='0'><tr><td>\n"
    footer += f"Input reduction options loaded from</td><td>{filelink(reduction_options_path)}</td></tr>\n"
    footer += "</table>\n"

    # load options and validate
    with open(reduction_options_path, "r") as f:
        raw_options = json.load(f)
    input_config = reduction_parameters(raw_options, validate=False, permissible=True)
    input_config = update_reduction_parameters(input_config, amendment, validate=True, permissible=True)
    final_input_config = deepcopy(input_config)  # input_config will be modified during reduction

    # load files and reduce
    logger.info("reduce_sample: loading input files with load_all_files()")
    os.chdir(AUTOREDUCE_DIR)  # required for load_all_files() to work
    loaded = load_all_files(input_config)
    logger.info("reduce_sample: reducing with reduce_single_configuration()")
    output = reduce_single_configuration(loaded, input_config)

    # create PNG images for all intensity profiles
    logger.info("reduce_sample: saving intensity profiles to PNG images with plot_reduction_output()")
    plot_reduction_output(output, input_config)  # save as *.PNG files

    # create a detector-pixel counts intensity plot, save as HTML report
    logger.info("reduce_sample: create detector pixel intensity plot with reduce_non_sample()")
    report = reduce_non_sample(events) + "<hr>\n"

    # create plotly images for all intensity profiles, save as HTML report
    logger.info("reduce_sample: creating Plotly output with plotly_reduction_output()")
    report += plotly_reduction_output(output, input_config) + "<hr>\n"

    # Save the input reduction options
    logger.info("reduce_sample: saving final input reduction options to JSON file")
    reduction_options_path = os.path.join(output_dir, f"reduction_options_{run_number}.json")
    with open(reduction_options_path, "w") as config_file:
        json.dump(final_input_config, config_file, indent=4, sort_keys=True)

    return report + footer


def footer(events: EventWorkspace, output_dir: str, log_context: LogContext) -> str:
    """Generate an HTML footer with reduction metadata and file locations.

    Creates an HTML table containing information about the reduction process, including
    software versions, file paths, timing information, and reduction parameters.

    Parameters
    ----------
    events : EventWorkspace
        The Mantid EventWorkspace containing the raw events data. Used to extract
        run number, IPTS number, proton charge statistics, and sample logs.
    output_dir : str
        Base output directory path where reduction files are saved. If this matches
        the IPTS-specific autoreduce directory, a subdirectory with the run number
        will be used for the actual output files.
    log_context : LogContext
        A named tuple containing:
        - logger: Logger for logging reduction status and errors.
        - logfile: Path to the reduction log file.
        - error_buffer: StringIO buffer containing error-level log messages.

    Returns
    -------
    str
        An HTML string containing a table with reduction metadata, including:
        - drtsans version and documentation links
        - Log file location
        - Proton charge duration
        - Reduction options file paths
        - Output files directory
        - Reduction timestamp
    """
    logger, logfile = log_context.logger, log_context.logfile
    run_number = str(events.getRunNumber())
    reduction_options_path = os.path.join(output_dir, f"reduction_options_{run_number}.json")
    logger.info("footer: generating reduction footer information")
    docs = "<a href='https://drtsans.readthedocs.io/latest/index.html' target='_blank'>drtsans</a>"
    version = drtsans.__version__
    release = f"<a href='https://github.com/neutrons/drtsans/releases/tag/v{version}' target='_blank'>{version}</a>"
    footer = "<table border='0'>\n"
    footer += f"<tr><td>Reduced with </td><td>{docs} version {release}</td></tr>\n"
    footer += f"<tr><td>Reduction log</td><td>{filelink(logfile)}</td></tr>\n"
    proton_charge = SampleLogs(events).proton_charge
    footer += f"<tr><td>Duration from proton charge</td><td>{proton_charge.getStatistics().duration} sec</td></tr>\n"
    footer += "<tr><td>Comprehensive input reduction options saved to</td><td>"
    footer += f"{filelink(reduction_options_path)}</td></tr>\n"
    footer += f"<tr><td>Output reduction files saved to</td><td>{filelink(output_dir)}</td></tr>\n"
    footer += f"<tr><td>Date </td><td>{datetime.datetime.now().strftime('%Y-%m-%d %I:%M %p')}</td></tr>\n"
    footer += "</table>\n<hr>\n"
    return footer


def match_run_number(path: str) -> str:
    """Extract the run number from a given file path.

    Parameters
    ----------
    path : str
        The file path from which to extract the run number.

    Returns
    -------
    str
        The extracted run number as a string. If no run number is found, returns "unknown".

    Notes
    -----
    - The function searches for a pattern matching 'EQSANS_<run_number>' in the provided path.
    - The run number is expected to be a sequence of digits following 'EQSANS_'.
    """
    match = re.search(r"EQSANS_(\d+)", path)
    return match.group(1) if match else ""


def reduce_events(events: EventWorkspace, output_dir: str, log_context: LogContext) -> str:
    """Execute the reduction workflow and generate an HTML report.

    Performs the complete reduction process for either sample or non-sample runs,
    handles errors, generates an HTML report with plots and metadata, and optionally
    publishes the report to the livedata server.

    Parameters
    ----------
    events : EventWorkspace
        The Mantid EventWorkspace containing the raw events to be reduced.
    output_dir : str
        Directory path where output files (HTML report, reduced data, plots) will be saved.
    log_context : LogContext
        A named tuple containing:
        - logger: Logger instance for logging reduction progress and errors
        - logfile: Path to the log file
        - error_buffer: StringIO buffer capturing error-level messages
    publish : bool
        If True, upload the HTML report to the livedata server. If False, only save locally.

    Raises
    ------
    RuntimeError
        If the reduction process encounters errors. The exception message includes
        the path to the log file and captured error messages.

    Notes
    -----
    - Automatically determines whether to use sample or non-sample reduction workflow
    - Captures all errors and includes them in the HTML report
    - Reports total reduction time upon successful completion
    - Saves the HTML report as `EQSANS_{run_number}.html` in the output directory
    - If publishing is enabled, uploads the report to the EQSANS livedata server
    """
    start_time = time.time()
    logger, error_buffer = log_context.logger, log_context.error_buffer

    # reduce events
    report = ""
    try:
        report += reduce_sample(events, output_dir, logger) if is_sample_run(events) else reduce_non_sample(events)
    except Exception:
        logger.error("Reduction failed")

    # If reduction failed, include error log messages and traceback in the HTML report
    error_messages = error_buffer.getvalue()
    if error_messages:
        report += f"<div><h3>Error Messages</h3><pre>{error_messages}</pre></div></hr>\n"
    else:
        minutes, seconds = divmod(time.time() - start_time, 60)
        report += f"<div>Reduction completed in: <b>{int(minutes)} min {int(seconds)} sec.</b><br></div>\n"
    return report


def autoreduce(args: argparse.Namespace):
    """Execute the complete autoreduction workflow for EQSANS event data.

    This is the main entry point for the autoreduction process. It orchestrates loading event data,
    performing reduction (either sample or non-sample), generating reports, handling errors, and
    optionally publishing results to the livedata server.

    Parameters
    ----------
    args : argparse.Namespace
        Command-line arguments containing:
        - events_file (str): Path to the Nexus events file to be reduced
        - outdir (str): Base output directory for reduction files and reports
        - no_publish (bool): If True, skip uploading the report to the livedata server

    Raises
    ------
    FileNotFoundError
        If the specified events file does not exist

    Notes
    -----
    - Configures logging to capture all reduction process information and errors
    - Automatically determines if the run is a sample or non-sample run
    - For IPTS autoreduce directories, creates a run-specific subdirectory
    - Saves an HTML report containing plots, metadata, and any error messages
    - Reports total reduction time upon completion
    - If reduction fails, captures the exception in the error log
    - Optionally uploads the report to the livedata server (default: enabled)
    """
    # sanity checks
    if not os.path.isfile(args.events_file):
        raise FileNotFoundError(f"data file {args.events_file} not found")
    run = match_run_number(args.events_file)
    if not run:
        raise ValueError("Run number could not be determined from the events file path")

    # Load events file
    logger = logging.getLogger(LOG_NAME)
    logger.info(f"Loading events from {args.events_file}")
    events = LoadEventNexus(Filename=args.events_file, OutputWorkspace=mtd.unique_hidden_name())

    # amend the output directory, if necessary
    ipts = SampleLogs(events).experiment_identifier.value[5:]  # e.g. "12345" when having IPTS-12345
    output_dir = args.outdir.rstrip("/")  # remove trailing slash, if any
    if output_dir == AUTOREDUCE_IPTS_DIR.format(ipts=ipts):  # e.g. /SNS/EQSANS/IPTS-12345/shared/autoreduce/
        output_dir = os.path.join(args.outdir, run)  # e.g. /SNS/EQSANS/IPTS-12345/shared/autoreduce/198434/
    os.makedirs(output_dir, exist_ok=True)

    # instantiate the logging context
    run_number = str(events.getRunNumber())  # e.g. "105584"
    error_buffer, logfile = configure_logger(LOG_NAME, output_dir, run_number)
    log_context = LogContext(logger=logger, logfile=logfile, error_buffer=error_buffer)

    # reduce events, save report, and optionally publish to livedata server
    report = reduce_events(events, output_dir, log_context)
    report += footer(events, output_dir, log_context)

    # Save report to disk as an HTML file
    logger.info("Saving HTML report to disk")
    save_report(report, os.path.join(output_dir, f"EQSANS_{run_number}.html"), logger)

    #  Upload report to the livedata server if requested
    if not args.no_publish:
        logger.info("Uploading HTML report to livedata server")
        upload_report(run_number, report, logger)

    # Exit ungracefully if there were errors
    error_messages = error_buffer.getvalue()
    if error_messages:
        raise RuntimeError(f"Reduction completed with errors, see {logfile} for details\n{error_messages}")
    else:
        logger.info("Reduction completed successfully")


if __name__ == "__main__":
    args = parse_command_arguments()
    autoreduce(args)
